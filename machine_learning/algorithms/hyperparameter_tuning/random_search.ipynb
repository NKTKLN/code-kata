{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d34ba7a",
   "metadata": {},
   "source": [
    "# üß™ Custom Random Search\n",
    "\n",
    "In this notebook, we implement **Random Search with cross-validation** from scratch using **a custom class `MyRandomSearchCV`**. We then compare the performance of these implementations with **scikit-learn**'s `RandomSearchCV` model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ae7e75",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Importing Libraries & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import (\n",
    "    BaseCrossValidator,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d14d1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.width\", 150)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f36ff",
   "metadata": {},
   "source": [
    "### üì• Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b607b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28f6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56902d14",
   "metadata": {},
   "source": [
    "### üß† Implementing Custom Model Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRandomizedSearchCV:\n",
    "    \"\"\"Randomized search with cross-validation for hyperparameter optimization.\n",
    "\n",
    "    Randomly samples hyperparameter combinations from the specified grid\n",
    "    and evaluates each using cross-validation to find the best model\n",
    "    based on accuracy score.\n",
    "\n",
    "    Attributes:\n",
    "        estimator (BaseEstimator): The base model implementing fit and predict.\n",
    "        param_distributions (dict[str, list[Any]]): Hyperparameters and their\n",
    "            candidate values.\n",
    "        n_iter (int): Number of random hyperparameter combinations to sample.\n",
    "        cv (int | BaseCrossValidator): Number of folds or cross-validation strategy.\n",
    "        best_estimator_ (BaseEstimator | None): Estimator fitted on full data with\n",
    "            best params.\n",
    "        best_params_ (dict[str, Any] | None): Best hyperparameter combination found.\n",
    "        best_score_ (float): Highest mean cross-validation accuracy score achieved.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator: BaseEstimator,\n",
    "        param_distributions: dict[str, list[Any]],\n",
    "        n_iter: int,\n",
    "        cv: int | BaseCrossValidator = 5,\n",
    "        random_state: int | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the randomized search object.\n",
    "\n",
    "        Args:\n",
    "            estimator (BaseEstimator): Base model with fit and predict methods.\n",
    "            param_distributions (dict[str, list[Any]]): Dictionary specifying\n",
    "                hyperparameters and the list of values to sample from.\n",
    "            n_iter (int): Number of random parameter combinations to evaluate.\n",
    "            cv (int | BaseCrossValidator, optional): Number of folds or CV splitter.\n",
    "                Defaults to 5.\n",
    "            random_state (int | None, optional): Random seed for reproducibility.\n",
    "                Defaults to None.\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.param_distributions = param_distributions\n",
    "        self.n_iter = n_iter\n",
    "        self.cv = cv\n",
    "        self.rng = np.random.default_rng(random_state)\n",
    "\n",
    "        self.best_estimator_: BaseEstimator | None = None\n",
    "        self.best_params_: dict[str, Any] | None = None\n",
    "        self.best_score_: float = float(\"-inf\")\n",
    "\n",
    "    def fit(self, X: NDArray[np.float64], y: NDArray[np.int64 | np.float64]) -> None:\n",
    "        \"\"\"Run randomized search with cross-validation on the training data.\n",
    "\n",
    "        Samples random hyperparameter combinations, evaluates each via CV,\n",
    "        and stores the best model and corresponding parameters.\n",
    "\n",
    "        Args:\n",
    "            X (NDArray[np.float64]): Feature matrix of shape (n_samples, n_features).\n",
    "            y (NDArray[np.int64 | np.float64]): Target vector of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        if isinstance(self.cv, int):\n",
    "            cv = KFold(n_splits=self.cv, shuffle=True, random_state=42)\n",
    "        else:\n",
    "            cv = self.cv\n",
    "\n",
    "        used_params = []\n",
    "        iterations = self.n_iter\n",
    "        while iterations > 0:\n",
    "            params = {\n",
    "                k: self.rng.choice(v) for k, v in self.param_distributions.items()\n",
    "            }\n",
    "            if params in used_params:\n",
    "                continue\n",
    "\n",
    "            estimator = clone(self.estimator)\n",
    "            estimator.set_params(**params)\n",
    "\n",
    "            scores = []\n",
    "            for train_idx, valid_idx in cv.split(X, y):\n",
    "                X_train, X_test = X[train_idx], X[valid_idx]\n",
    "                y_train, y_test = y[train_idx], y[valid_idx]\n",
    "\n",
    "                estimator.fit(X_train, y_train)\n",
    "                y_pred = estimator.predict(X_test)\n",
    "\n",
    "                score = accuracy_score(y_test, y_pred)\n",
    "                scores.append(score)\n",
    "\n",
    "            avg_score = np.mean(scores)\n",
    "            if self.best_score_ < avg_score:\n",
    "                self.best_score_ = avg_score\n",
    "                self.best_params_ = params\n",
    "                self.best_estimator_ = estimator\n",
    "                self.best_estimator_.fit(X, y)\n",
    "\n",
    "            iterations -= 1\n",
    "            used_params.append(params)\n",
    "\n",
    "    def predict(self, X: NDArray[np.float64]) -> NDArray[np.int64 | np.float64]:\n",
    "        \"\"\"Predict target values using the best found estimator.\n",
    "\n",
    "        Args:\n",
    "            X (NDArray[np.float64]): Feature matrix for prediction.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If fit() has not been called yet.\n",
    "\n",
    "        Returns:\n",
    "            NDArray[np.int64 | np.float64]: Predicted target values.\n",
    "        \"\"\"\n",
    "        if self.best_estimator_ is None:\n",
    "            raise ValueError(\"fit() must be called before predict()\")\n",
    "        return self.best_estimator_.predict(X)\n",
    "\n",
    "    def score(self, X: NDArray[np.float64], y: NDArray[np.int64 | np.float64]) -> float:\n",
    "        \"\"\"Compute accuracy of the best estimator on the given data.\n",
    "\n",
    "        Args:\n",
    "            X (NDArray[np.float64]): Feature matrix.\n",
    "            y (NDArray[np.int64]): True labels.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If fit() has not been called yet.\n",
    "\n",
    "        Returns:\n",
    "            float: Accuracy score.\n",
    "        \"\"\"\n",
    "        if self.best_estimator_ is None:\n",
    "            raise ValueError(\"fit() must be called before score()\")\n",
    "        return self.best_estimator_.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37469d",
   "metadata": {},
   "source": [
    "### üèãÔ∏è‚Äç‚ôÇÔ∏è Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e200ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "model = SVC()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "# 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Scikit-learn RandomizedSearchCV\n",
    "sklearn_rs = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=6,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    ")\n",
    "sklearn_rs.fit(X_train, y_train)\n",
    "\n",
    "# My RandomizedSearchCV\n",
    "my_rs = MyRandomizedSearchCV(\n",
    "    estimator=model, param_distributions=param_grid, n_iter=6, cv=cv, random_state=42\n",
    ")\n",
    "my_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37549ace",
   "metadata": {},
   "source": [
    "### üìä Comparing Algorithm Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4baa28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>kernel</th>\n",
       "      <th>gamma</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sklearn</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>10.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C kernel  gamma best_cv_score test_score\n",
       "sklearn    10    rbf  scale      0.966667        1.0\n",
       "custom   10.0    rbf  scale      0.966667        1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_algorithms = {\"sklearn\": sklearn_rs, \"custom\": my_rs}\n",
    "\n",
    "columns = list(param_grid.keys()) + [\"best_cv_score\", \"test_score\"]\n",
    "performance_summary = pd.DataFrame(\n",
    "    index=random_search_algorithms.keys(), columns=columns\n",
    ")\n",
    "\n",
    "for model_name, random_search_instance in random_search_algorithms.items():\n",
    "    best_params_and_scores = random_search_instance.best_params_.copy()\n",
    "    best_params_and_scores[\"best_cv_score\"] = random_search_instance.best_score_\n",
    "    best_params_and_scores[\"test_score\"] = random_search_instance.score(X_test, y_test)\n",
    "\n",
    "    performance_summary.loc[model_name] = pd.Series(best_params_and_scores)\n",
    "\n",
    "performance_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-project-template-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
